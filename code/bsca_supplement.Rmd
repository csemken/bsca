---
title: 'Analysis of multiple specifications'
subtitle: 'Online Supplement'
author: 
  - Christoph Semken
  - David Rossell
date: "`r format(Sys.time(), '%d %B %Y')`"
fontsize: 12pt
indent: true
bibliography: specurveanalysis.bib
link-citations: yes
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    number_sections: yes
    fig_caption: yes
    df_print: kable
header-includes:
   - \usepackage{float,placeins}
   - \usepackage[capitalise]{cleveref}
   - \hypersetup{colorlinks,citecolor=blue,linkcolor=blue,urlcolor=blue}
   - \renewcommand{\thefigure}{S\arabic{figure}}
   - \renewcommand{\thetable}{S\arabic{table}}
---

```{r setup, echo=FALSE, message=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)  # add options to kable (e.g. caption for tables)

PATH= '.'

setwd(file.path(PATH,'code'))
source(file.path(PATH,'code/functions.R'))

kbl =  knitr::kable  # shortcut for kable
plot_path = file.path(PATH, 'data/export/plots')

# Print data.frames and matrices nicely
knit_print.data.frame = function(x, ...) {
  res = paste(c('', '', kable(x, booktabs=T, digits = 3, table.envir = "table", position = "H")), 
              collapse = '\n')
  asis_output(res)
}
registerS3method("knit_print", "data.frame", knit_print.data.frame)
registerS3method("knit_print", "matrix", knit_print.data.frame)

# Get data
yrbs = new.env(); mcs = new.env()
load(file.path(PATH, 'data/export/yrbs.Rdata'), yrbs)
load(file.path(PATH, 'data/export/mcs.Rdata'), mcs)

```

\newpage

\noindent
This document contains supplementary information for our paper “Analysis of multiple specifications: statistical validity and a Bayesian proposal”.
In \cref{sec:main} we describe how BMS and BMA are used to produce a Bayesian Specification Curve Analysis (BSCA) and how to replicate our main results on teenager well-being using R.
\Cref{sec:robustness} contains supplementary data analyses that assess the robustness of our main findings for the Youth Risk Behavior Survey (YBRS) and Millenium Cohort Study (MCS) datasets. These robustness analyses include comparing linear to non-linear treatment effects and considering other well-being outcomes than those presented in the main paper.
\Cref{sec:issues} describes certain aspects in which our analysis differs from that of @orben_association_2019. One motivation for these differences was to consider the inclusion of further control covariates, which as discussed in the main paper, is necessary to reduce biases in parameter estimates. We also adjusted the definition of some of the variables – e.g. expressing them on a common scale to facilitate interpretation and comparability, using validated psychometric scales as opposed to (unvalidated) individual outcome variables, fixing minor errors related to variable codes and including unemployed parents in the analysis.


# Reproducing the BSCA results for the teenager well-being datasets  \label{sec:main}

```{r child = 'bsca_analysis.Rmd'}
```




# Robustness checks  \label{sec:robustness}

In this section, we provide robustness checks for the results presented in the main paper.

## YRBS: alternative outcomes

In their analysis of the YRBS data, besides ‘thought about suicide’, @orben_association_2019 used several well-being measures to study the effect of technology use:  loneliness, planned suicide, attempted to commit suicide and saw a doctor about suicide.  We have reproduced Fig. 1 for these outcomes in \cref{fig:yrbs_bsca_other}.  All associations are qualitatively similar, although the magnitudes vary.

```{r, echo=FALSE, fig.height=6, fig.width=8, fig.cap='\\label{fig:yrbs_bsca_other} BSCA for other outcomes using YRBS data: (a) loneliness, (b) planned suicide, (c) attempted to commit suicide and (d) saw a doctor about suicide. Otherwise, everything – including the order of control variables in the bottom panel – is as in Fig. 1 of the main text.'}
#yrbs$supplement$bsca_other
knitr::include_graphics(file.path(plot_path, 'yrbs_bsca_other.png'))
```


## YRBS: linear regression

All outcome variables in the YRBS are binary (e.g. 0 = did not think about suicide, 1 = thought about suicide). @orben_association_2019 used linear regression, which is unsuitable for binary outcomes. Instead, we used logistic regression to model the probability of the outcome being one. The logistic regression coefficient is easily interpretable; it is the log odds-ratio associated of said probability relative to the reference group, for example the log odds-ratio of the probability that a teenager who watches a moderate amount of TV thinking about suicide relative to a teenager who does not watch TV. 

For robustness, \cref{fig:yrbs_bsca_lin} shows the single-outcome BSCA for a linear regression model. Our main results remain qualitatively unaltered: electronic device use is associated with an increase in the probability of thinking about suicide, whereas moderate TV use is associated with a decrease.

```{r, message=FALSE, echo=FALSE, warn=FALSE, fig.height=4, fig.width=7, fig.cap='\\label{fig:yrbs_bsca_lin}YRBS data. BSCA for the effect technology uses on thinking about suicide. Estimates are obtained using the linear probability model, by iterating over all possible models – including with only one TV coefficient removed. Otherwise, everything is specified as in Fig. 1 of the main text.'}
yrbs$supplement$bsca_lin
```


## YRBS: lineary of association with TV use

Preliminary exploratory data analyses (see the supplementary file `bsca_preanalysis.html`) revealed that in both the YRBRS and MCS datasets almost all treatments had a monotone, near-linear association. The only exception was TV usage in the YRBS data, which displayed a U-shaped association with adolescent well-being, see \cref{fig:yrbs_lin_tv_think}.

```{r, echo=FALSE, fig.height=3, fig.width=7, fig.cap='\\label{fig:yrbs_lin_tv_think}YRBS data. Estimated coefficient for different values of TV use on thinking about suicide. Coefficients were estimated by MLE for a model including all treatment and control variables. Estimated coefficients are qualitatively similar for other outcomes.'}
yrbs$supplement$lin_tv_think
```

Therefore, we estimated separate coefficients for medium and high TV use based on coefficient similarity in \cref{fig:yrbs_lin_tv_think} (see the main text for the exact coding). For completeness, we also performed a BSCA with an assumed linear TV effect. As expected, the association was in between that for medium and high usage, as shown in \cref{fig:yrbs_bsca_tv_num}. Note that the estimate still suggests that higher TV use is associated with lower odds of thinking about suicide, as in our main analysis.

```{r, echo=FALSE, fig.height=4, fig.width=7, fig.cap='\\label{fig:yrbs_bsca_tv_num}YRBS data. Bayesian SCA for the effect of technology uses on thinking about suicide. TV use is numeric, with 0 = no usage and 1 = 5 hours or more. Otherwise, everything is specified as in Fig. 1 of the main text.'}
yrbs$supplement$bsca_tv_num
```


## MCS: full BSCAs

Fig. 2 of the main paper shows the summary of coefficients for different (parent- and self-assessed) outcomes.  We showed the multiple-outcome BSCA for brevity. \cref{fig:mcs_bsca_logit} shows the single-outcome BSCAs for those outcomes discussed in the text (self-assessed depression and low self-esteem, parent-assessed high total difficulities and emotional problems), whereas \cref{fig:mcs_bsca_parent_logit} shows those for the remaining parent-assessed outcomes.

```{r, echo=FALSE, fig.height=6, fig.width=8, fig.cap='\\label{fig:mcs_bsca_logit} MCS data. BSCAs for outcomes: (a) adolescent-assessed depression, (b) adolescent-assessed low self-esteem, (c) parent-assessed high total difficulties and (d) parent-assessed high emotional problems. For variable codings and confounders, see Fig. 2 of the main text.'}
knitr::include_graphics(file.path(plot_path, 'mcs_bsca_logit.png'))
```

```{r, echo=FALSE, fig.height=6, fig.width=8, fig.cap='\\label{fig:mcs_bsca_parent_logit} MCS data.  BSCAs for parent-assessed outcomes (SDQ): (a) conduct problems (b) hyperactivity/inattention, (c) peer problems and (d) prosociality. For variable codings and confounders, see Fig. 2 of the main text.'}
knitr::include_graphics(file.path(plot_path, 'mcs_bsca_parent_logit.png'))
```


## MCS: linear regression

Unlike in the YRBS dataset, which has binary outcomes, the outcomes in the MCS dataset are numerical. Parent assessments use the Strengths and Difficulties Questionnaire (SDQ), which provides a score for several well-being categories. Adolescent self-assessments come in three different forms: depressive symptoms according to the short version of the Mood and Feelings Questionnaire (SMFQ), self-esteem according to the Rosenberg scale, and a non-standardized “wellbeing grid” (with the prompt “On a scale of 1 to 7 where ‘1’ means completely happy and ‘7’ means not at all happy, how do you feel about the following parts of your life?” and various outcomes, e.g. ‘Your life as a whole’). Individual questions use 3 item (SDQ and SMFQ), 4 item (Rosenberg) or 7 item (wellbeing grid) Likert scales and the aggregate scores (where available) also have different supports.

In our main analysis we converted the outcomes into a binary outcome where 1 codes for an abnormal outcome and 0 for a normal outcome. This conversion was done for two reasons.  First, we could use logistic regression for both the YRBS and MCS data, making the results (i.e. odds ratios between low and high usage) comparable.  Second, because the scales are mostly standardized, there exist recommended cutoffs derived from population data to define our binary bad (abnormal) / good (normal) outcome.  The cutoffs (given in Fig. 2 of the main text) come from @goodman_strengths_1997 and @goodman_strengths_1998 for the SDQ, @rosenberg_society_1965 and @nguyen_low_2019 for the Rosenberg scale, and @thabrew_validation_2018 for the SMFQ.  The ‘well-being grid’ outcomes are not included in Fig. 2, since they do not come from standardized scales and no population-based abnormality cutoffs are available, see next section.  

For robustness, we also obtained results using the linear regression model on the original numerical outcomes. The linear regression results for the outcomes discussed in the main paper are shown in \cref{fig:mcs_bsca_main_lin}.  One important difference is that social media is not included in the results for the self-esteem outcome.  This is likely due to the high co-linearity with other internet (Pearson’s correlation =
`r round(cor(na.omit(mcs$data[,c('fcsome00r', 'fcinth00rm')]), method='pearson'),2)[1,2]`).
Otherwise, our main results retain their estimated signs.

In addition, \cref{fig:mcs_bsca_parent_lin,fig:mcs_bsca_teen_lin} show the linear results for the remaining parent-assessed and adolescent-assessed outcomes, respectively. Notably, unlike in the logistical model, in \cref{fig:mcs_bsca_parent_lin} other (non-social media) internet usage and owning a computer are negatively and positively associated with parent-assessed prosociality. As shown in \cref{fig:mcs_bsca_teen_lin}, technology use has very different estimated effects on different types of self-assessed happiness.  Social media, for example, is positively associated with being happy with ones friends, but negatively with being happy with ones looks. In contrast, none of the technology uses considered are associated with happiness regarding school, school work or family.

```{r, echo=FALSE, fig.height=6, fig.width=8, fig.cap='\\label{fig:mcs_bsca_main_lin} MCS data. Linear regression BSCA for main outcomes: (a) adolescent-assessed depression, (b) adolescent-assessed self-esteem (inverted), (c) parent-assessed total difficulties and (d) parent-assessed emotional problems.'}
knitr::include_graphics(file.path(plot_path, 'mcs_bsca_main_lin.png'))
```

```{r, echo=FALSE, fig.height=6, fig.width=8, fig.cap='\\label{fig:mcs_bsca_parent_lin} MCS data. Linear regression BSCA for parent-assessed outcomes (SDQ): (a) conduct problems (b) hyperactivity/inattention, (c) peer problems and (d) prosociality.'}
#mcs$supplement$bsca_parent_lin
knitr::include_graphics(file.path(plot_path, 'mcs_bsca_parent_lin.png'))
```

```{r, echo=FALSE, fig.height=9, fig.width=8, fig.cap='\\label{fig:mcs_bsca_teen_lin} MCS data. Linear regression BSCA for adolescent-assessed outcomes (well being grid): happy with (a) school work (b) looks, (c) family, (d) friends, (e) school and (f) life as a whole.'}
#mcs$supplement$bsca_teen_lin
knitr::include_graphics(file.path(plot_path, 'mcs_bsca_teen_lin.png'))
```



# Further differences with Orben and Przybylski (2019)  \label{sec:issues}

Our analysis is based on the YRBS and MCS datasets also used by @orben_association_2019 and largely followed their treatment of the data, which was facilitated by their commendable sharing of the R code used for the analysis.
However, we deviated from their data treatment choices (in the MCS data) when we felt these were potentially problematic.  We also enlarged the set of possible control variables in both datasets. 
In this section, we explain these differences.

## Re-scaling of variables

@orben_association_2019 transformed all outcome variables into a common 1-10 point scale prior to their analysis, so that it is easier to compare outcome values, estimated treatment effects, and combining them across outcomes. Unfortunately, this pre-processing step was not coherently applied to all MCS outcomes (see `1_3_prep_mcs.R` in their replication files), which led to several outcomes not being in the 1-10 scale (some actually have negative values, whereas one outcome takes on values as large as 41, see \cref{tab:mcs_outcomes_summary}). As a consequence, the estimated treatment effects for these outcomes are not really comparable to the outcomes that were in the 1-10 scale, leading to difficulties in interpreting their SCA plot. 

```{r, echo=FALSE}
questions = c('fpsdro00', 'fpsdhs00', 'fpsdtt00', 'fpsdsp00', 'fpsdmw00', 'fpsdfs00', 'fpsdfb00', 'fpsdud00', 'fpsddc00', 'fpsdnc00', 'fpsdoa00', 'fpsdpb00', 'fpsdcs00', 'fpsdgb00', 'fpsdfe00')
scores = c('fconduct', 'fhyper', 'fprosoc', 'fpeer', 'femotion', 'febdtot')
t = as.data.frame(sapply(mcs$data[, c(questions, scores)], function(x) {c(summary(x), length(na.omit(x)), sd(x, na.rm=T))}))
t = round(t(t)[,c(8,4,9,1,2,3,5,6)], digits=2)
colnames(t) = c('Obs.', 'Mean', 'S.D.', 'Min', '25%', 'Median', '75%', 'Max')
kbl(t, caption='\\label{tab:mcs_outcomes_summary} Summary statistics for parent-assessed MCS outcome variables used in Orben and Przybylski (2019)', booktabs=T)
```


## Questionary outcomes: individual questions versus validated scales \label{sec:issues-measures}

The analysis by @orben_association_2019 used as outcomes individual questions that make up common scales (e.g. all the values ending in 00 in \cref{tab:mcs_outcomes_summary}).  This is done for the adolescent-assessed Mood and Feelings Questionnaire – short version (SMFQ), the adolescent-assessed Rosenberg scale and the parent-assessed Strengths and Difficulties Questionnaire (SDQ).  While we think it is generally useful to look at different outcomes, we do not recommend breaking up questions that make up established scales, unless there is a strong reason for doing so.  This is because the combined scores have well-established psychometric properties, such as internal consistency, test-retest reliability and validity [see @stone_psychometric_2010;  @sinclair_psychometric_2010; @thabrew_validation_2018 for the SDQ, Rosenberg scale and SMFQ, respectively]. Hence, our analyses focused on the combined scores, rather than on individual questions.  This point was also addressed by @orben_reply_2020 themselves.


## Multiple treatment variables

As described in Section 1, in situations where there are multiple treatment variables it is statistically preferable to include them jointly in the model, to ameliorate the confounding between their estimated effects. The YRBS data has two treatments: TV and electronic devise use. The MCS data has five treatments: TV, electronic games, social media, other internet and own computer. In our analyses we always jointly included all treatments.


## Control variables

In our analysis, we included more control variables than @orben_association_2019.  For the YRBS analysis, the only control variable they sometimes included is race.  We added age, sex, grade, year of the survey and body-mass index (BMI), several of which were statistically significant (see Fig. 1 and \cref{fig:yrbs_bsca_other}).  For the MCS analysis, @orben_association_2019 included a larger set of control variables (see Fig. 2), to which we added sex, age and BMI, which again turned out to be important.  We also departed from their analysis in how we treated two MCS control covariates: primary caretaker's employment and education status.

Regarding employment, @orben_association_2019 used the NS-SEC 5 category for the current job (1="Manager" through 5="Routine"), meaning that all kids with unemployed primary caretakers (for which the variable is coded `NA`) are excluded from the analysis. This is actually a non-negligible proportion of the dataset, see \cref{tab:mcs_empl_count}.  We believe that such exclusion may introduce biases, by restricting the scope of the inference to kids with employed parents caretakers.  Instead, in our analysis we included a binary variable to control for employment status (1=employed or self-employed; 0 otherwise), which allows including kids with unemployed parents into the analysis. 

Regarding education status, the covariate is also coded on a 1-5 scale, but there are two special values (95= “Overseas qualification” and 96=“None of these”), see \cref{tab:mcs_educ_count}.
@orben_association_2019 included the 95-96 values in their linear regression analysis, which is inappropriate: one cannot interpret the estimated coefficients as capturing the association between the outcome and the caretaker's education status. Possible alternative analyses are to either exclude individuals with these codes (excluding a non-negligible proportion of individuals), or use a non-linear coding for the covariate's effect. 
For simplicity, and given that we already included numerous other control covariates, in our analysis we excluded the education variable. 

```{r, echo=FALSE}
t = t(table(mcs$data$fd05s00, useNA=c('always')))
kbl(t, caption='\\label{tab:mcs_empl_count} Primary caretaker employment status (1-5). Number of individuals with each value', booktabs=T)
```

```{r, echo=FALSE}
t = t(table(mcs$data$fdacaq00, useNA=c('always')))
kbl(t, caption='\\label{tab:mcs_educ_count} Primary caretaker education status (1-5). Number of individuals with each value', booktabs=T)
```



\FloatBarrier
# References {.unlisted .unnumbered}
<!-- bibliography inserted here -->
